{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing prices in Boston : utilisation de l'interface graphique d'OpenTURNS\n",
    "\n",
    "\n",
    "This dataset contains information collected by various sources concerning housing in the area of Boston Mass in 1970. The sources are the U.S Census Service, FBI and other sources. The dataset contains 506 cases. \n",
    "\n",
    "There are 14 variables:\n",
    "* CRIM : per capita crime rate by town\n",
    "* ZN : proportion of residential land zoned for lots over 25,000 sq.ft. (high value restricts construction of small lot houses)\n",
    "* INDUS : proportion of non retail business acres per town (measures the impact of noise, heavy traffic and visual effects)\n",
    "* CHAS : Charles River dummy variable (1 if tract bounds river; 0 otherwise). Captures the amenities of a riverside location.\n",
    "* NOX : nitric oxides concentration (parts per 10 million) (measures air pollution)\n",
    "* RM : average number of rooms per dwelling (measures the spaciousness)\n",
    "* AGE : proportion of owner occupied units built prior to 1940 (related to structure quality)\n",
    "* DIS : weighted distances to five Boston employment centres\n",
    "* RAD : index of accessibility to radial highways\n",
    "* TAX : full value property tax rate per 10,000 US Dollars (measures the cost of public services)\n",
    "* PTRATIO : pupil teacher ratio by town (measures public sector benefits in each town)\n",
    "* B : $1000(Bk - 0.63)^2$ US Dollars where Bk is the proportion of blacks by town\n",
    "* LSTAT : percent lower status of the population (proportion of adults without some high school education and proportion of male workers classified as laborers)\n",
    "* MEDV : median value of owner occupied homes in 1,000 US Dollars\n",
    "\n",
    "The classical goal is to predict MEDV depending on the first 13 variables.\n",
    "\n",
    "## Reference\n",
    "\n",
    "* Regression Analysis with Python, Luca Massaron, Alberto Boschetti, Packt Publishing\n",
    "* Harrison, Jr., David, Rubinfeld, Daniel L. (1978/03).\"Hedonic housing prices and the demand for clean air.\" Journal of Environmental Economics and Management 5(1): 81-102. \n",
    "* Belsley, Kuh & Welsch, \"Regression diagnostics: Identifying Influential Data and Sources of Collinearity\", Wiley, 1980. 244-261.\n",
    "* Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "On souhaite analyser les données du fichier suivant dans l'interface graphique.\n",
    "\n",
    "    Housing-prices-Boston.csv\n",
    "\n",
    "L'objectif de cette étude est de déterminer quels facteurs sont les plus influents sur le prix d'une maison dans la réunion de Boston en 1978. Pour cela, nous proposons d'utiliser des outils d'exploration graphique interactive, ainsi que des méthodes d'analyse de sensibilité.\n",
    "\n",
    "Dans l'interface graphique, créer une nouvelle étude, puis sélectionner \"Modèle de données\".\n",
    "\n",
    "<img src=\"Boston-new-datamodel.PNG\" width=\"600\">\n",
    "\n",
    "Dans le diagramme d'utilisation, sélectionner \"Définition du modèle\".\n",
    "\n",
    "<img src=\"Boston-diagram.PNG\" width=\"400\">\n",
    "\n",
    "Sélectionner le fichier suivant sur votre disque :\n",
    "\n",
    "    Housing-prices-Boston.csv\n",
    "\n",
    "<img src=\"Boston-select-CSV.PNG\" width=\"400\">\n",
    "\n",
    "Dans l'arbre d'étude, choisissez l'élément \"Définition\" et, avec le bouton droit de la souris, choisissez \"Analyse de données\".\n",
    "\n",
    "<img src=\"Boston-analyse-donnees.PNG\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : analyse du modèle de données\n",
    "\n",
    "* Quelles sont les principales caractéristiques de l'échantillon des prix des maisons ?\n",
    "* Quelle est la distribution des prix des maisons ? Quelles sont ses caractéristiques ?\n",
    "* Analyser les boxplots : quelles sont les variables qui sont associées à des données qui ne sont pas gaussiennes du tout ?\n",
    "* Analyser la matrice de dépendance des coefficients de corrélation de Spearman. \n",
    "  * Quelles sont les variables qui semblent moins dépendantes ? \n",
    "  * Quelles sont les variables qui semblent plus dépendantes ?\n",
    "  * Peut-on utiliser les indices de sensibilité de Sobol' dans cette situation ?\n",
    "* Analyser le cobweb.\n",
    "  * Quelles sont les variables qui sont associées à une discrétisation des valeurs ?\n",
    "  * Quelles sont les variables qui semblent mener à des prix MEDV élevés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution de l'exercice 1 : analyse du modèle de données\n",
    "\n",
    "Les principales caractéristiques du prix d'une maison sont les suivantes.\n",
    "\n",
    "| Statistique | MEDV (1000\\$) |\n",
    "|---|---|\n",
    "| Min | 5 |\n",
    "| Max | 50 |\n",
    "| Moyenne | 22.5328 |\n",
    "| Écart type | 9.1971 |\n",
    "\n",
    "<img src=\"Boston-exercice-1-summary-solution.png\" width=\"500\">\n",
    "\n",
    "<img src=\"Boston-exercice-1-PDF-MEDV-solution.png\" width=\"500\">\n",
    "\n",
    "Le prix des maisons dans cet échantillon suit une distribution associée à deux pics.\n",
    "* Un premier mode apparaît entre 18 et 23 mille \\$.\n",
    "* On observe un second pic de prix, moindre, entre 45 et 50 mille \\$.\n",
    "* On observe une distribution des prix entre 5 et 50 mille \\$.\n",
    "\n",
    "Graphique boîte à moustache\n",
    "* 50% de la population est contenue dans la boîte bleue, associée aux quantiles à 25% et 75%,\n",
    "* la médiane (quantile à 50%) est le trait horizontal rouge,\n",
    "* si l'échantillon suit la loi gaussienne, alors les moustaches correspondent approximativement aux quantiles à 1% et 99%,\n",
    "* si l'échantillon contient des données aberrantes, alors ces points apparaissent comme des étoiles rouges au dessus et en dessous des moustaches.\n",
    "\n",
    "On observe que la variable de sortie MEDV, ainsi que B, ZN et CRIM contiennent des données atypiques, qui s'éloignent beaucoup de la loi gaussienne.\n",
    "\n",
    "<img src=\"boiteAmoustaches-MEDV-solution.png\" width=\"300\">\n",
    "<img src=\"boiteAmoustaches-B-solution.png\" width=\"300\">\n",
    "<img src=\"boiteAmoustaches-ZN-solution.png\" width=\"300\">\n",
    "<img src=\"boiteAmoustaches-CRIM-solution.png\" width=\"300\">\n",
    "\n",
    "L'analyse de la matrice des coefficients de Spearman révèle des dépendantes.\n",
    "* B, PRATIO et CHAS semblent moins dépendantes des autres variables.\n",
    "* INDUS, NOX, AGE, RAD et TAX semblent plus dépendantes des autres variables.\n",
    "\n",
    "<img src=\"spearman-matrix-solution.PNG\" width=\"800\">\n",
    "\n",
    "Dans le cobweb, analysons les données dans l'espace des rangs. Pour une variable donnée, les valeurs sont triées par ordre croissant. Cela implique que, pour une variable donnée, si il n'y a aucune paire de valeurs égales dans l'échantillon, alors les rangs sont uniforméments distribués. En conséquence, l'apparition de clusters dans l'espace des rangs révèle que certains valeurs dans l'échantillon sont égales. Cela peut être causée par exemple par une variable entière, ou bien par une variable réelle qui a été discrétisée lors de l'enregistrement de la valeur (par exemple, par un appareil de mesure physique associé à une précision limitée). \n",
    "\n",
    "<img src=\"cobweb-sans-selection-solution.PNG\" width=\"1000\">\n",
    "\n",
    "Nous observons que les variables suivantes sont discrétisées : ZN, INDUS, CHAS (qui vaut 0 ou 1), RAD, TAX, PTRATIO, B.\n",
    "* Le fait que la variable CHAS soit discrétisée est un résultat attendu, puisque c'est une variable booléenne.\n",
    "* Dans la table, nous trions les valeurs numériques par ordre décroissant pour la variable ZN. On observe qu'une forte proportion de valeurs sont égales à zéro. En utilisant le widget probabilité/quantile, on obtient que 72% des valeurs de ZN sont égales à 0.\n",
    "\n",
    "<img src=\"Analyse-ZN-quantiles-solution.PNG\" width=\"600\">\n",
    "\n",
    "Dans le cobweb, analysons les données dans l'espace des rangs. Nous sélectionnons les valeurs de MEDV supérieures au quantile à 90%. Pour avoir un prix élevé, il est préférable d'avoir :\n",
    "* une valeur basse de INDUS (peu d'industrie), NOX (peu de pollution), LSTAT (moins de personnes peu éduquées)\n",
    "* une valeur élevée de RM (la surface de la maison)\n",
    "\n",
    "<img src=\"cobweb-solution.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Création d'un métamodèle\n",
    "\n",
    "* Créer un métamodèle de krigeage.\n",
    "  * Quelle valeur de Q2 observez-vous ? \n",
    "  * Est-ce un métamodèle satisfaisant ?\n",
    "* Créer un métamodèle de chaos polynomial creux de degré 3. \n",
    "  * Quelle valeur de Q2 observez-vous ?\n",
    "  * Est-ce un métamodèle satisfaisant ?\n",
    "  * Observez la taille de base polynomiale en fonction du degré du polynôme : combien de termes sont retenus ?\n",
    "  * Observez la moyenne, l'écart-type et la décomposition de la variance : qu'observez-vous ? Que peut-on conclure ?\n",
    "  * Analyser les multi-indices dans la décomposition : que peut-on conclure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution de l'exercice 2 : Création d'un métamodèle\n",
    "\n",
    "Le métamodèle de krigeage requiert une longue phase de calcul pour réaliser le calcul d'optimisation de la vraisemblance nécessaire pour estimer les hyperparamètres. On obtient un coefficient de prédictivité Q2 de 88%, ce qui est plutôt satisfaisant. \n",
    "\n",
    "<img src=\"krigeage-solution.PNG\" width=\"1000\">\n",
    "\n",
    "Pour pouvoir réaliser l'analyse de sensibilité, il faut identifier les lois de probabilité associées à chaque variable, ainsi qu'une éventuelle dépendance. Au vu de la matrice de dépendance de Spearman, il est impossible d'utiliser les indices de Sobol' sur cet échantillon (sans faire de traitement supplémentaire) car les dépendances sont trop fortes. \n",
    "\n",
    "La figure suivante présente un chaos polynomial creux de degré 3. Dans l'onglet \"Validation\", on observe un Q2 analytique de 84%. \n",
    "\n",
    "<img src=\"boston-chaos-degre-3-solution.png\" width=\"500\">\n",
    "\n",
    "La figure suivante présente l'analyse des moments d'un chaos polynomial creux de degré 3. On observe que la moyenne du chaos est égale à 2.960 et que l'écart-type est égal à 5.600. Or on sait que la moyenne des prix est égale à 22.53. L'écart entre la moyenne des données et la moyenne du chaos est dû à l'absence d'indépendance dans les variables d'entrée. En conséquence, les moments du chaos polynomial ne coïncident pas avec les moments de l'échantillon. Par conséquent, les valeurs numériques des moments indiqués dans cet onglet sont à ignorer.\n",
    "\n",
    "<img src=\"boston-chaos-moments-solution.png\" width=\"600\">\n",
    "\n",
    "On observe également que le multi-indice associé à la plus grande part de variance (17.25%) est associé à un polynôme de degré 3. Cela montre que, pour correctement représenter la fonction, le chaos polynomial a été contraint de sélectionner un coefficient de degré élevé. Cela indique que des fortes non-linéarités sont présentent dans l'échantillon. \n",
    "\n",
    "* TODO : pour un métamodèle, qu'est-ce que le résidu ? Qu'est-ce que l'erreur relative ?\n",
    "* TODO : avec 13 variables, l'inférence est fastidieuse, car il faut ajouter toute la liste de distributions pour chaque variable\n",
    "* TODO : quand on convertit le métamodèle en modèle physique, le nom du métamodèle est perdu : la description est \"metamodele_0 metamodel\", alors que j'ai placé le nom \"kriging0\"\n",
    "* TODO : aucun avertissement n'est présenté dans l'onglet \"Résumé\" du chaos, alors qu'une forte dépendance est présente. Pourquoi ne pas indiquer la paire de variable (Xi,Xj) associée au coefficient de corrélation de Pearson le plus élevé ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : inférence des marginales\n",
    "\n",
    "Pour chacune des variables RM, LSTAT et CRIM, répondre aux questions suivantes :\n",
    "* Quelle loi s'ajuste le mieux à cet échantillon ?\n",
    "* L'ajustement est-il satisfaisant ?\n",
    "* Peux-t-on améliorer l'ajustement et comment ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution de l'exercice 3 : inférence des marginales\n",
    "\n",
    "La figure suivante présente l'ajustement de la distribution de la variable RM. On observe que c'est la loi de Laplace qui s'ajuste le mieux, à la fois en terme de critère BIC et en terme de p-valeur pour le test de Kolmogorov-Smirnov.\n",
    "\n",
    "<img src=\"RM-distribution-solution.PNG\" width=\"1000\">\n",
    "\n",
    "Le QQ-plot pour la variable RM montre une adéquation qui est plutôt satisfaisante.\n",
    "\n",
    "<img src=\"RM-diagrammeQQ-solution.png\" width=\"400\">\n",
    "\n",
    "La loi qui s'ajuste le mieux à la variable LSTAT est la loi de Weibull. L'ajustement est de bonne qualité.\n",
    "\n",
    "<img src=\"LSTAT-distribution-solution.PNG\" width=\"1000\">\n",
    "\n",
    "La figure suivante présente l'ajustement de la distribution de la variable CRIM. Aucune loi ne s'ajuste correctement. Pour améliorer la qualité de l'ajustement, on pourrait utiliser une méthode d'estimation à noyaux.\n",
    "\n",
    "<img src=\"CRIM-distribution-solution.PNG\" width=\"1000\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
