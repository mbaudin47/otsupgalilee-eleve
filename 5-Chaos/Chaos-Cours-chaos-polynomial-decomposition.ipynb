{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction aux polynômes de chaos : décomposition en chaos polynomial\n",
    "\n",
    "## Résumé\n",
    "\n",
    "Dans cette page, nous présentons la décomposition en polynômes du chaos d'une fonction multivariée. Nous présentons l'esimation des moments et des indices de sensibilité d'un chaos polynomial.\n",
    "\n",
    "## Références\n",
    "\n",
    "OpenTURNS :\n",
    "* http://openturns.github.io/openturns/master/theory/meta_modeling/chaos_basis.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Références\n",
    "\n",
    "Ouvrages, articles, thèses :\n",
    "* O.P Le Maître, O.M.Knio, Spectral methods for uncertainty quantification, Springer, 2010\n",
    "* Wuan Luo. Wiener Chaos Expansion and Numerical Solutions of Stochastic Stochastic Partial Differential Equations. PhD thesis, California Institute of Technology, May 2006.\n",
    "* R. H. Cameron and W. T. Martin. The orthogonal development of nonlinear functionals in series of Fourier-Hermite functionals. Annals of Mathematics, 48(2):385-392, April 1947.\n",
    "* Adaptive sparse polynomial chaos expansions for uncertainty propagation and sensitivity analysis, Thèse, Géraud Blatman, 2009\n",
    "\n",
    "Pour les plus aventuriers, vous pouvez prendre de risque de consulter mon propre texte qui contient la démonstration de plusieurs résultats présentés ici.\n",
    "* Introduction to polynomials chaos with NISP. Michael Baudin. Version 0.5. March 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothèses\n",
    "\n",
    "On considère la fonction $g$  :\n",
    "\n",
    "$$\n",
    "Y = g(X)\n",
    "$$\n",
    "\n",
    "où $Y\\in\\mathbb{R}$ et $X\\in\\mathbb{R}^p$ où $p$ est la dimension de la variable aléatoire en entrée. \n",
    "Soit $T$ la transformation iso-probabiliste associée et $\\xi \\in\\mathbb{R}^p$ telle que \n",
    "$\\xi = T(X)$ pour tout $X\\in\\mathbb{R}^p$. \n",
    "\n",
    "On considère une variable aléatoire standardisée $\\xi\\in\\mathbb{R}^p$. On considère la fonction $h$  :\n",
    "\n",
    "$$\n",
    "Y = h(\\xi) \n",
    "$$\n",
    "\n",
    "où $h$ est définie par :\n",
    "\n",
    "$$\n",
    "h(\\xi) = g\\circ T^{-1}(\\xi) = g\\left(T^{-1}(\\xi)\\right).\n",
    "$$\n",
    "\n",
    "Dans l'équation précédente, la fonction $g\\circ T^{-1}$ est la composition de la fonction $g$ par l'inverse de la transformation iso-probabiliste $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "*Note* : On considère ici le cas où la sortie $Y$ est un scalaire. \n",
    "\n",
    "Le cas plus général où la sortie $Y$ est un vecteur se traite de manière analogue, pour chaque composante du vecteur de sortie. \n",
    "\n",
    "Plus précisément, cela revient à créer plusieurs polynômes du chaos, chaque polynôme étant associé à une composante du vecteur de sortie. \n",
    "\n",
    "Cela ne nécessite pas nécessairement de nouveaux appels à la la fonction $g$, mais requiert des calculs supplémentaires. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supposons que :\n",
    "* la variance de la sortie $Y$ est finie,\n",
    "* les marginales de $\\xi$ sont indépendantes. \n",
    "\n",
    "Sous ces hypothèses, notons $f_i$ la loi marginale de la variable aléatoire $\\xi_i\\in\\mathbb{R}$, pour $i=1,...,n$. Puisque les variables sont indépentantes, la densité de probabilité du vecteur aléatoire $\\xi$ est le produit des lois marginales, c'est à dire :\n",
    "$$\n",
    "f(\\xi) = \\prod_{i=1}^p f_i(\\xi_i)\n",
    "$$\n",
    "pour tout $\\xi\\in\\mathbb{R}^p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Décomposition en chaos polynomial\n",
    "\n",
    "La décomposition précédente est une décomposition *spectrale*, analogue à la décomposition de Fourier. Lorsque la variable $X$ suit une loi gaussienne de marginales indépendantes, on utilise la base des polynômes d'Hermite multivariés (créés par tensorisation des polynômes d'Hermites univariés). Dans ce cas, cette décomposition s'appelle *décomposition en polynômes de chaos*. \n",
    "\n",
    "Dans le cas général où les marginales ne sont pas nécessairement gaussiennes, cette décomposition se nomme *décomposition en polynômes de chaos généralisés*. \n",
    "\n",
    "La preuve de la convergence des polynômes du cas (i.e. dans le cas particulier gaussien) est dûe, dans un cadre un peu plus général, à Cameron et Martin (voir (Le Maître, Knio, 2010) page 29). Le théorème de Cameron-Martin implique une variable aléatoire $\\xi$ en dimension infinie, c'est à dire que $\\xi=(\\xi_1,\\xi_2,...)$. \n",
    "\n",
    "Soit $\\{\\psi_j(\\xi)\\}_{j\\geq 0}$ une famille de polynômes orthogonaux multivariés. On définit le produit scalaire entre deux polynômes : \n",
    "$$\n",
    "\\left( \\psi_{j}(\\xi),\\psi_{k}(\\xi) \\right) = \\mathbb{E} (\\psi_{j}(\\xi) \\psi_{k}(\\xi))\n",
    "$$\n",
    "pour $j,k\\geq 1$. Par définition de l'espérance, on a :\n",
    "$$\n",
    "\\left( \\psi_{j}(\\xi),\\psi_{k}(\\xi) \\right) = \\int_{\\mathbb{R}^n} \\psi_{j}(\\xi) \\psi_{k}(\\xi) f(\\xi) d\\xi.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On fait l'hypothèse que les polynômes multivariés $\\psi_j$ sont orthogonaux, c'est à dire que le produit scalaire est égal à zéro pour deux polynômes différents :\n",
    "$$\n",
    "\\left( \\psi_j(\\xi),\\psi_k(\\xi) \\right) = 0,\n",
    "$$\n",
    "pour $j\\neq k$.\n",
    "\n",
    "Alors la sortie peut être décomposée sous la forme d'une combinaison linéaire des polynômes multivariés :\n",
    "$$\n",
    "Y = \\sum_{j=0}^{\\infty} a_j\\psi_j(\\xi),\n",
    "$$\n",
    "où $a_j\\in\\mathbb{R}$ sont les coefficients de la décomposition en polynômes du chaos et $\\xi=(\\xi_1,\\xi_2,...)$ est une variable aléatoire en dimension infinie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La première troncature consiste à restreindre le vecteur aléatoire $\\xi=(\\xi_1,...,\\xi_p)$ à une dimension $p$ finie. \n",
    "La seconde troncature consiste à restreindre le nombre de termes dans la série, pour ne conserver que les $P$ premiers termes, où $P$ est un entier. \n",
    "Alors la sortie peut être décomposée sous la forme d'une combinaison linéaire des polynômes multivariés (voir (Le Maître, Knio, 2010) page 34) :\n",
    "$$\n",
    "Y = \\sum_{j=0}^P a_j\\psi_j(\\xi) + \\epsilon(p,P),\n",
    "$$\n",
    "où $\\xi=(\\xi_1,...,\\xi_p)$, $\\epsilon(p,P)$ est une variable aléatoire et \n",
    "$$\n",
    "a_j=\\frac{(g,\\psi_j)}{\\|\\psi_j\\|^2},\n",
    "$$\n",
    "pour $j\\geq 0$.\n",
    "De plus, la décomposition précédente converge dans le sens $L^2$ :\n",
    "$$\n",
    "\\lim_{p,P\\rightarrow \\infty} \\|\\epsilon(p,P)\\| = 0.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Proposition: Coefficients of the truncated decomposition**\n",
    "\n",
    "Assume that the truncated decomposition is exact, i.e.\n",
    "$$\n",
    "g(\\xi) = \\sum_{j=0}^P a_j\\psi_j(\\xi)\n",
    "$$\n",
    "for any $\\xi\\in\\mathbb{R}^p$.\n",
    "Therefore, the truncated expansion is such that\n",
    "$$\n",
    "a_j=\\frac{(g,\\psi_j)}{\\|\\psi_j\\|^2},\n",
    "$$\n",
    "for $k=0,...,P$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Preuve**\n",
    "Indeed, for $k=0,...,P$, we have:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "(g,\\psi_k)\n",
    "&=& \\int_{\\mathbb{R}^p} g(\\xi) \\psi_k(\\xi) f(\\xi)d\\xi\\\\\n",
    "&=& \\int_{\\mathbb{R}^p} \\left(\\sum_{j=0}^P a_j\\psi_j(\\xi)\\right) \\psi_k(\\xi) f(\\xi)d\\xi\\\\\n",
    "&=& \\sum_{j=0}^{P} a_j \\int_{\\mathbb{R}^p} \\psi_j(\\xi) \\psi_k(\\xi) w(x)d\\xi\\\\\n",
    "&=& \\sum_{j=0}^{P} a_j (\\psi_j,\\psi_k) \\\\\n",
    "&=& a_k (\\psi_k,\\psi_k) \\\\\n",
    "&=& a_k \\|\\psi_k\\|^2,\n",
    "\\end{eqnarray*}\n",
    "\n",
    "since $(\\psi_j,\\psi_k)=0$ if $j\\neq k$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Considérons maintenant le cas particulier où les polynômes multivariés $\\psi_j$ sont orthonormaux. \n",
    "On note $\\delta_{j,k}$ le symbole de Kronecker :\n",
    "$$\n",
    "\\delta_{j,k} = \n",
    "\\begin{cases} \n",
    "1 & \\mbox{si } j=k,  \\\\ \n",
    "0 & \\mbox{si } j \\ne k\n",
    "\\end{cases}\n",
    "$$\n",
    "pour tout $j,k\\geq 0$.\n",
    "Par définition d'une famille de polynômes orthonormaux, on a \n",
    "$$\n",
    "\\left( \\psi_j(\\xi),\\psi_k(\\xi) \\right) = \\delta_{j,k},\n",
    "$$\n",
    "pour $j,k=0,...,P$.\n",
    "Alors $\\|\\psi_j\\|=1$ pour $j\\geq 0$. \n",
    "Par conséquent, les coefficients de la décomposition en polynômes du chaos sont \n",
    "$$\n",
    "a_j=(g,\\psi_j),\n",
    "$$\n",
    "pour $j=0,...,P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moments et indices de sensibilité d'un chaos polynomial\n",
    "\n",
    "Dans cette section, nous présentons comment calculer la moyenne, la variance et les indices de sensibilité du premier ordre et totaux d'un chaos polynomial.\n",
    "\n",
    "Supposons que l'on a décomposé la fonction $g$ en chaos polynomial $\\tilde{g}$. Si le chaos polynomial est une mauvaise approximation de la fonction, alors il ne peut être utilisé. C'est la raison pour laquelle le thème de la quantification de la qualité d'un métamodèle est un sujet important en pratique. Au contraire, si le métamodèle est une bonne approximation de la fonction $g$, alors on peut, en poussant notre avantage, substituer $\\tilde{g}$ à la place de $g$. De cette manière, toutes les caractéristiques que nous souhaiterions connaître sur $g$, nous pouvons les tirer de $\\tilde{g}$. \n",
    "\n",
    "La plupart des propriétés de la variable aléatoire peuvent être directement déduites des coefficients $a\\in\\mathbb{R}^{P+1}$ où $P+1$ est le nombre de coefficients. En particulier, si la base polynomiale est orthonormée (et non pas seulement orthogonale), les caractéristiques sont particulièrement faciles à obtenir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supposons que la décomposition en chaos polynomiale est :\n",
    "$$\n",
    "\\tilde{g}(\\xi) = \\sum_{j=0}^P a_j\\psi_j(\\xi)\n",
    "$$\n",
    "for any $\\xi\\in\\mathbb{R}^p$. \n",
    "\n",
    "La moyenne du chaos polynomial est \n",
    "$$\n",
    "E\\left[\\tilde{g}(\\xi)\\right]= a_0,\n",
    "$$\n",
    "c'est à dire le premier coefficient de la décomposition.\n",
    "\n",
    "De plus, \n",
    "$$\n",
    "V\\left[\\tilde{g}(\\xi)\\right]=\\sum_{j=1}^P a_j^2 \\|\\psi_j\\|^2.\n",
    "$$\n",
    "Dans l'expression précédente, soulignons que la variance est une somme de carrés, à *l'exclusion* du terme $a_0$ qui n'apparaît pas. \n",
    "Si la base polynomiale est orthonormale, alors l'expression est particulièrement simple :\n",
    "$$\n",
    "V\\left[\\tilde{g}(\\xi)\\right]=\\sum_{j=1}^P a_j^2.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pour calculer les indices de sensibilité, on observe que la variance $V\\left[\\tilde{g}(\\xi)\\right]$ est décomposée comme une somme de carrés par le chaos polynomial, chaque terme ne dépendant que de $\\psi_j$. C'est pourquoi le calcul des indices de sensibilité est particulièrement simple, en ne considérant que les termes appropriés dans chaque cas. \n",
    "\n",
    "Pour exprimer les indices de sensibilité, il est plus facile de le faire en utilisant les multi-indices. \n",
    "Notons $\\mathcal{J}$ l'ensemble des multi-indices de dimension $p$ :\n",
    "$$\n",
    "\\mathcal{J}=\\left\\{\\alpha=(\\alpha_1,...,\\alpha_p), \\alpha_i\\in\\{0,1,2,...\\}\\right\\}.\n",
    "$$\n",
    "Soit $\\mathcal{J}_P$ l'ensemble des multi-indices associés à la troncature à l'ordre $P$ du chaos polynomial. \n",
    "Plus précisément, la taille de l'ensemble $\\mathcal{J}_P$ est égale à $P+1$, c'est à dire que $card\\left(\\mathcal{J}_P\\right)=P+1$. \n",
    "Supposons que la décomposition en chaos polynomiale est :\n",
    "$$\n",
    "\\tilde{g}(\\xi) = \\sum_{\\alpha\\in\\mathcal{J}_P} a_\\alpha \\psi_\\alpha(\\xi)\n",
    "$$\n",
    "pour tout $\\xi\\in\\mathbb{R}^p$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pour $i=1,...,p$, on souhaite calculer l'indice de sensibilité du premier ordre $S_i$ et total $T_i$. \n",
    "\n",
    "Pour calculer $S_i$, il faut considérer l'ensemble des multi-indices $\\alpha$ associés uniquement à la variable $\\xi_i$. \n",
    "Ainsi, les polynômes considérés dépendent exclusivement de $\\xi_i$ et pas des autres variables, ce qui permet de mesurer l'effet de la variable $\\xi_i$ seule. \n",
    "Plus précisément, soit $\\mathcal{J}_i^S$ l'ensemble des multi-indices tels que $\\alpha_i>0$ et tel que les autres composantes du multi-indice sont nulles :\n",
    "$$\n",
    "\\mathcal{J}_i^S=\\left\\{\\alpha=(0,...0,\\alpha_i,0,...,0)\\in\\mathcal{J}_P, \\quad \\alpha_i>0\\right\\}.\n",
    "$$\n",
    "Alors l'indice du premier ordre $S_i$ est la somme des carrés des coefficients associés à la i-ème variable :\n",
    "$$\n",
    "S_i = \\frac{\\sum_{\\alpha\\in\\mathcal{J}_i^S} a_\\alpha^2 \\|\\psi_\\alpha\\|^2}{V\\left[\\tilde{g}(\\xi)\\right]}.\n",
    "$$\n",
    "Si la base polynomiale est orthonormale, alors :\n",
    "$$\n",
    "S_i = \\frac{\\sum_{\\alpha\\in\\mathcal{J}_i^S} a_\\alpha^2}{V\\left[\\tilde{g}(\\xi)\\right]}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pour calculer $T_i$, il faut considérer l'ensemble des multi-indices $\\alpha$ associés à la variable $\\xi_i$, y compris ses interactions avec les autres variables. \n",
    "Ainsi, les polynômes considérés dépendent tous de $\\xi_i$ et, dans certains cas, également des autres variables, ce qui permet de mesurer l'effet de la variable $\\xi_i$ y compris ses interactions. \n",
    "Plus précisément, soit $\\mathcal{J}_i^T$ l'ensemble des multi-indices tels que $\\alpha_i> 0$ :\n",
    "$$\n",
    "\\mathcal{J}_i^T=\\left\\{\\alpha=(\\alpha_1,...,\\alpha_i,...,\\alpha_p)\\in\\mathcal{J}_P, \\quad \\alpha_i>0\\right\\}.\n",
    "$$\n",
    "Alors l'indice total $T_i$ est la somme des carrés des coefficients associés à la i-ème variable :\n",
    "$$\n",
    "T_i = \\frac{\\sum_{\\alpha\\in\\mathcal{J}_i^T} a_\\alpha^2 \\|\\psi_\\alpha\\|^2}{V\\left[\\tilde{g}(\\xi)\\right]}.\n",
    "$$\n",
    "Si la base polynomiale est orthonormale, alors :\n",
    "$$\n",
    "T_i = \\frac{\\sum_{\\alpha\\in\\mathcal{J}_i^T} a_\\alpha^2}{V\\left[\\tilde{g}(\\xi)\\right]}.\n",
    "$$\n",
    "\n",
    "On peut également obtenir des indices similaires, non plus seulement pour une variable donnée, mais pour un groupe de variables. Cette idée permet d'identifier, par exemple, quelles variables d'entrée peuvent être fixées et rendues égales à leur valeur moyenne."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
